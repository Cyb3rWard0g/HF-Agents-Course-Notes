{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit 1: 4 - Defining Tools for SmolLM2\n",
    "\n",
    "**Collaborators**:\n",
    "* Roberto Rodriguez ([@Cyb3rWard0g](https://x.com/Cyb3rWard0g))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Tools\n",
    "\n",
    "AI Agents extend their capabilities through **Tools**, which are predefined functions that perform specific tasks beyond the model's internal knowledge. Tools allow LLMs to:\n",
    "- Fetch up-to-date information\n",
    "- Perform calculations\n",
    "- Interact with APIs\n",
    "- Retrieve external knowledge\n",
    "\n",
    "### Example Use Cases\n",
    "| **Tool**         | **Description**                                     |\n",
    "|----------------|-------------------------------------------------|\n",
    "| Web Search    | Fetches real-time data from the internet       |\n",
    "| Calculator    | Performs arithmetic operations                 |\n",
    "| API Interface | Calls external services (GitHub, Weather API)  |\n",
    "| Retrieval     | Retrieves specific data from a database       |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a Simple Tool\n",
    "\n",
    "A Tool consists of:\n",
    "- A **name**\n",
    "- A **description**\n",
    "- Expected **arguments** and their types\n",
    "- An **output type**\n",
    "- A **callable function**\n",
    "\n",
    "Here’s a basic **calculator tool** that multiplies two numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example Calculation: 12\n"
     ]
    }
   ],
   "source": [
    "def calculator(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two integers.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "# Example usage\n",
    "print(\"Example Calculation:\", calculator(3, 4))  # Output: 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Generic Tool Class\n",
    "\n",
    "Instead of manually writing descriptions for each tool, we can define a **Tool class** that extracts this information automatically using Python’s introspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "\n",
    "class Tool:\n",
    "    \"\"\"\n",
    "    A class representing a reusable AI Tool.\n",
    "    \"\"\"\n",
    "    def __init__(self, name: str, description: str, func: callable):\n",
    "        self.name = name\n",
    "        self.description = description\n",
    "        self.func = func\n",
    "        self.arguments = inspect.signature(func).parameters\n",
    "        self.outputs = inspect.signature(func).return_annotation\n",
    "    \n",
    "    def to_string(self) -> str:\n",
    "        \"\"\"\n",
    "        Generates a structured textual representation of the tool.\n",
    "        \"\"\"\n",
    "        args_str = \", \".join([f\"{arg}: {param.annotation}\" for arg, param in self.arguments.items()])\n",
    "        return f\"Tool Name: {self.name}, Description: {self.description}, Arguments: {args_str}, Outputs: {self.outputs}\"\n",
    "    \n",
    "    def __call__(self, *args, **kwargs):\n",
    "        \"\"\"Invoke the tool.\"\"\"\n",
    "        return self.func(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool Name: calculator, Description: Multiply two integers., Arguments: a: <class 'int'>, b: <class 'int'>, Outputs: <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "calculator_tool = Tool(\"calculator\", \"Multiply two integers.\", calculator)\n",
    "print(calculator_tool.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a Decorator for Simplicity\n",
    "\n",
    "To simplify tool creation, we can use a **Python decorator**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool Name: calculator, Description: Multiply two integers., Arguments: a: <class 'int'>, b: <class 'int'>, Outputs: <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "# Define a decorator to register tools\n",
    "\n",
    "def tool(func):\n",
    "    \"\"\"Decorator to register a function as a tool.\"\"\"\n",
    "    return Tool(func.__name__, func.__doc__, func)\n",
    "\n",
    "@tool\n",
    "def calculator(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two integers.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "# Example usage\n",
    "print(calculator.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrating Tools into SmolLM2 System Messages\n",
    "\n",
    "To make SmolLM2 aware of available tools, we can include them in the **system prompt**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading SmolLM2 Efficiently\n",
    "\n",
    "To avoid downloading the model every time (**~3.42 GB**), we first check if it exists locally before loading:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from local directory.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cf9587ed0f54afe95d1584d971519a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "import os\n",
    "\n",
    "MODEL_NAME = \"HuggingFaceTB/SmolLM2-1.7B-Instruct\"\n",
    "MODEL_DIR = \"data/smollm2\"\n",
    "\n",
    "def load_model():\n",
    "    if os.path.exists(MODEL_DIR):\n",
    "        print(\"Loading model from local directory.\")\n",
    "        model = AutoModelForCausalLM.from_pretrained(MODEL_DIR)\n",
    "    else:\n",
    "        print(\"Downloading model...\")\n",
    "        model = AutoModelForCausalLM.from_pretrained(MODEL_NAME)\n",
    "        model.save_pretrained(MODEL_DIR)\n",
    "    return model\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = load_model().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Tools to System Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a system message including tool descriptions\n",
    "system_message = {\n",
    "    \"role\": \"system\",\n",
    "    \"content\": \"You are an assistant with access to tools. Available tools: \\n\"\n",
    "    + calculator.to_string()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example user interaction\n",
    "messages = [\n",
    "    system_message,\n",
    "    {\"role\": \"user\", \"content\": \"What is 5 times 6?\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are an assistant with access to tools. Available tools: \n",
      "Tool Name: calculator, Description: Multiply two integers., Arguments: a: <class 'int'>, b: <class 'int'>, Outputs: <class 'int'><|im_end|>\n",
      "<|im_start|>user\n",
      "What is 5 times 6?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert messages into model-compatible format\n",
    "input_text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode with attention mask\n",
    "encoded_input = tokenizer(input_text, return_tensors=\"pt\").to(device)\n",
    "input_ids = encoded_input[\"input_ids\"]\n",
    "attention_mask = encoded_input[\"attention_mask\"]  # Explicit attention mask\n",
    "count_prompt_tokens = input_ids.shape[1]\n",
    "\n",
    "# Generate response with proper settings\n",
    "outputs = model.generate(\n",
    "    input_ids, \n",
    "    attention_mask=attention_mask,  # Avoids padding/EOS confusion\n",
    "    max_new_tokens=50,\n",
    "    eos_token_id=tokenizer.eos_token_id  # Stops at <|im_end|>\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant Response: <tool_call>[{\"name\": \"calculator\", \"arguments\": {\"a\": 5, \"b\": 6}}]</tool_call>\n"
     ]
    }
   ],
   "source": [
    "# Extract only assistant-generated tokens\n",
    "generated_tokens = outputs[0, count_prompt_tokens:]\n",
    "\n",
    "# Decode assistant response\n",
    "output = tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
    "print(\"Assistant Response:\", output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The assistant’s response contains the tool call wrapped in `<tool_call>` tags, following this format:\n",
    "\n",
    "`<tool_call>[{\"name\": \"calculator\", \"arguments\": {\"a\": 5, \"b\": 6}}]</tool_call>`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to extract the JSON object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_index = output.index(\"{\")\n",
    "end_index = output.rindex(\"}\")\n",
    "chosen_tool = output[start_index : end_index + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"name\": \"calculator\", \"arguments\": {\"a\": 5, \"b\": 6}}'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosen_tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we convert the tool call string into a Python dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'calculator', 'arguments': {'a': 5, 'b': 6}}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "parsed_tool = json.loads(chosen_tool)\n",
    "parsed_tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Updated Block Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Text:\n",
      " <|im_start|>system\n",
      "You are an assistant with access to tools. Available tools: \n",
      "Tool Name: calculator, Description: Multiply two integers., Arguments: a: <class 'int'>, b: <class 'int'>, Outputs: <class 'int'><|im_end|>\n",
      "<|im_start|>user\n",
      "What is 5 times 6?<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n",
      "Assistant Response:\n",
      " <tool_call>[{\"name\": \"calculator\", \"arguments\": {\"a\": 5, \"b\": 6}}]</tool_call>\n",
      "\n",
      "Parsed Tool Call:\n",
      " {'name': 'calculator', 'arguments': {'a': 5, 'b': 6}}\n"
     ]
    }
   ],
   "source": [
    "# Define a system message including tool descriptions\n",
    "system_message = {\n",
    "    \"role\": \"system\",\n",
    "    \"content\": \"You are an assistant with access to tools. Available tools: \\n\"\n",
    "    + calculator.to_string()\n",
    "}\n",
    "\n",
    "# Example user interaction\n",
    "messages = [\n",
    "    system_message,\n",
    "    {\"role\": \"user\", \"content\": \"What is 5 times 6?\"},\n",
    "]\n",
    "\n",
    "# Convert messages into model-compatible format\n",
    "input_text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "print(\"Input Text:\\n\", input_text)\n",
    "\n",
    "# Encode input with attention mask\n",
    "encoded_input = tokenizer(input_text, return_tensors=\"pt\").to(device)\n",
    "input_ids = encoded_input[\"input_ids\"]\n",
    "attention_mask = encoded_input[\"attention_mask\"]\n",
    "count_prompt_tokens = input_ids.shape[1]  # Save prompt length\n",
    "\n",
    "# Generate response\n",
    "outputs = model.generate(\n",
    "    input_ids, \n",
    "    attention_mask=attention_mask,\n",
    "    max_new_tokens=50,\n",
    "    eos_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "\n",
    "# Extract only assistant-generated tokens\n",
    "generated_tokens = outputs[0, count_prompt_tokens:]\n",
    "\n",
    "# Decode assistant response\n",
    "output = tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
    "print(\"Assistant Response:\\n\", output)\n",
    "\n",
    "# Extract tool invocation\n",
    "start_index = output.index(\"{\")\n",
    "end_index = output.rindex(\"}\")\n",
    "chosen_tool = output[start_index : end_index + 1]\n",
    "\n",
    "# Parse tool call into JSON\n",
    "import json\n",
    "parsed_tool = json.loads(chosen_tool)\n",
    "\n",
    "print(\"\\nParsed Tool Call:\\n\", parsed_tool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executing Tools\n",
    "Now that we have extracted and parsed the tool invocation, the next step is to execute the tool. The assistant generates the tool call, but it is up to us to process and execute it.\n",
    "\n",
    "We follow these steps:\n",
    "\n",
    "1. Retrieve the tool name and arguments from parsed_tool.\n",
    "2. Verify that the tool exists and is callable.\n",
    "3. Execute the tool with the extracted arguments.\n",
    "4. Capture the tool's output and return it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool Execution Result: 30\n"
     ]
    }
   ],
   "source": [
    "# Extract tool name and arguments\n",
    "tool_name = parsed_tool[\"name\"]\n",
    "arguments = parsed_tool[\"arguments\"]\n",
    "\n",
    "# Available tools (mapping tool names to functions)\n",
    "available_tools = {\n",
    "    \"calculator\": calculator\n",
    "}\n",
    "\n",
    "# Verify tool exists\n",
    "if tool_name not in available_tools:\n",
    "    raise ValueError(f\"Unknown tool: {tool_name}. Available tools: {list(available_tools.keys())}\")\n",
    "\n",
    "# Execute tool\n",
    "tool_function = available_tools[tool_name]\n",
    "result = tool_function(**arguments)\n",
    "\n",
    "print(f\"Tool Execution Result: {result}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
